# Node.js no es de un solo hilo

Node.js es conocido como una plataforma de servidor incre√≠blemente r√°pida gracias a su revolucionaria arquitectura de un solo hilo, que utiliza los recursos del servidor de manera m√°s eficiente. Pero, ¬ørealmente es posible lograr ese rendimiento sorprendente utilizando solo un hilo? La respuesta podr√≠a sorprenderte.

En este art√≠culo revelaremos todos los secretos y la ‚Äúmagia‚Äù detr√°s de Node.js de una manera muy simple.

## Proceso vs Hilo ‚öôÔ∏è

Antes de comenzar, tenemos que entender qu√© es un proceso y qu√© es un hilo, y descubrir sus diferencias y similitudes.

Un proceso es una instancia de un programa que se est√° ejecutando actualmente. Cada proceso se ejecuta de forma independiente de los dem√°s. Los procesos tienen varios recursos sustanciales:

* **C√≥digo de ejecuci√≥n;**
* **Segmento de datos** ‚Äî contiene variables globales y est√°ticas que necesitan ser accesibles desde cualquier parte del programa;
* **Heap (Mont√≠culo)** ‚Äî asignaci√≥n de memoria din√°mica;
* **Pila (Stack)** ‚Äî variables locales, argumentos de funciones y llamadas a funciones;
* **Registros** ‚Äî ubicaciones de almacenamiento peque√±as y r√°pidas directamente dentro de la CPU que se utilizan para mantener datos temporalmente durante la ejecuci√≥n de programas (como el puntero de programa y el puntero de pila).

Un **hilo** es una unidad √∫nica de ejecuci√≥n dentro de un proceso. Puede haber m√∫ltiples hilos dentro de un proceso que realizan diferentes operaciones simult√°neamente. El proceso comparte el c√≥digo de ejecuci√≥n, los datos y el heap con los hilos, pero la pila y los registros se asignan por separado para cada hilo.

<figure><img src="../.gitbook/assets/image (24).png" alt=""><figcaption></figcaption></figure>

## **JavaScript no es con hilos ‚ö†Ô∏è**

Para evitar malentendidos con los t√©rminos, es importante tener en cuenta que JavaScript en s√≠ mismo no es ni de un solo hilo ni multihilo. El lenguaje no tiene nada que ver con el manejo de hilos. Es simplemente un conjunto de instrucciones que la plataforma de ejecuci√≥n debe manejar. La plataforma maneja estas instrucciones a su manera ‚Äî ya sea de forma de un solo hilo o de forma multihilo.

## Operaciones de I/O üßÆ

(O operaciones de Entrada / Salida) son generalmente consideradas m√°s lentas en comparaci√≥n con otras operaciones del computador. Aqu√≠ algunos ejemplos:

* escribir datos en el disco;
* leer datos desde el disco;
* esperar una entrada del usuario (como un clic del mouse);
* enviar una solicitud HTTP;
* realizar una operaci√≥n en una base de datos.

## Las operaciones de I/O son lentas üê¢

Puede que te est√©s preguntando por qu√© leer datos desde el disco se considera lento. La respuesta est√° en la implementaci√≥n f√≠sica de los componentes de hardware.

Acceder a la memoria RAM se realiza en el orden de los nanosegundos, mientras que acceder a datos en el disco o a trav√©s de la red ocurre en el orden de los milisegundos.

Lo mismo se aplica al ancho de banda. La RAM tiene una tasa de transferencia que constantemente est√° en el orden de los GB/s, mientras que el disco o la red var√≠a desde MB/s hasta, en el mejor de los casos, GB/s.

Adem√°s de eso, tenemos que considerar el factor humano. En muchas circunstancias, la entrada de una aplicaci√≥n proviene de una persona real (por ejemplo, una pulsaci√≥n de tecla). As√≠ que la velocidad y frecuencia de las operaciones de I/O no dependen √∫nicamente de aspectos t√©cnicos.

## Las operaciones de I/O bloquean el hilo üöß

Las operaciones de I/O pueden ralentizar significativamente un programa. El hilo permanece bloqueado, y no se ejecutar√° ninguna otra operaci√≥n hasta que la operaci√≥n de I/O haya finalizado.

<figure><img src="../.gitbook/assets/image (25).png" alt=""><figcaption></figcaption></figure>

## ¬°Crea m√°s hilos! ü§™

Bien, ¬øpor qu√© no simplemente generar m√°s hilos dentro del programa y manejar cada solicitud por separado? Bueno, parece una buena idea. Ahora, cada solicitud de cliente tiene su propio hilo, y el servidor puede manejar m√∫ltiples solicitudes simult√°neamente.

<figure><img src="../.gitbook/assets/image (26).png" alt=""><figcaption></figcaption></figure>

El programa necesita asignar memoria adicional y recursos de CPU para cada hilo. Esto suena razonable. Sin embargo, surge un problema significativo cuando los hilos realizan operaciones de I/O: se vuelven inactivos y pasan la mayor parte del tiempo usando un 0% de los recursos, esperando a que la operaci√≥n se complete. Cuantos m√°s hilos haya, m√°s recursos se utilizan de manera ineficiente.

Adem√°s de eso, manejar hilos es una tarea compleja, lo que puede generar problemas potenciales como condiciones de carrera (_race conditions_), bloqueos mutuos (_deadlocks_) y bloqueos vivos (_livelocks_). El sistema operativo necesita alternar entre los hilos, lo cual puede a√±adir una sobrecarga y reducir las ganancias de eficiencia que se esperan del uso de m√∫ltiples hilos.

## ¬øCu√°l es la soluci√≥n? ü§î

Afortunadamente, la humanidad ya ha inventado mecanismos inteligentes para realizar este tipo de operaciones de manera eficiente.

Demos la bienvenida al Event Demultiplexer. Este mecanismo implica un proceso llamado Multiplexaci√≥n ‚Äî un m√©todo mediante el cual varias se√±ales se combinan en una sola se√±al sobre un recurso compartido. El objetivo es compartir un recurso escaso (en nuestro caso, la CPU y la RAM).

Por ejemplo, en telecomunicaciones, varias llamadas telef√≥nicas pueden ser transmitidas utilizando un solo cable.

<figure><img src="../.gitbook/assets/image (27).png" alt="" width="375"><figcaption></figcaption></figure>

Las responsabilidades del Event Demultiplexer se dividen en los siguientes pasos:

1. **Identificar las fuentes de eventos.** Cada fuente puede generar eventos;
2. **Registrar las fuentes de eventos.** El registro implica especificar qu√© eventos se deben monitorear para cada fuente;
3. **Esperar eventos;**
4. **Enviar notificaciones de eventos.**

¬°Importante! El Event Demultiplexer no es un componente o dispositivo que exista en el mundo real. Es m√°s bien un modelo te√≥rico utilizado para explicar c√≥mo manejar numerosos eventos simult√°neos de manera eficiente.

Para entender este proceso complejo, volvamos al pasado. Imagina una antigua central telef√≥nica: identifica y registra fuentes de eventos (tel√©fonos) y espera nuevos eventos (llamadas). Una vez que ocurre un nuevo evento (una llamada telef√≥nica), la central env√≠a una notificaci√≥n (enciende una bombilla). Entonces, el operador de la central reacciona a la notificaci√≥n revisando el n√∫mero de tel√©fono de destino y redirigiendo la llamada hacia su destino deseado.

Para las computadoras, el principio es el mismo. Sin embargo, el rol de las fuentes lo desempe√±an elementos como descriptores de archivos, sockets de red, temporizadores o dispositivos de entrada del usuario. Cada fuente puede generar eventos como: datos disponibles para leer, espacio disponible para escribir o solicitudes de conexi√≥n.

Cada sistema operativo ya ha implementado su propio mecanismo de Event Demultiplexer:

* epoll (Linux),
* kqueue (macOS),
* event ports (Solaris),
* IOCP (Windows).

Pero Node.js es multiplataforma. Para gobernar todo este proceso mientras se admite I/O entre distintas plataformas, existe una capa de abstracci√≥n que encapsula estas complejidades interplataforma e intraplataforma, y expone una API generalizada para las capas superiores de Node.js.

## ¬°Libuv el Rey! üèÜ

Demos la bienvenida a libuv ‚Äî una biblioteca multiplataforma (escrita en C) desarrollada originalmente para Node.js con el fin de proporcionar una interfaz consistente para operaciones de I/O no bloqueantes en varios sistemas operativos.

Libuv no solo se comunica con el Event Demultiplexer del sistema operativo, sino que tambi√©n incorpora dos componentes importantes: la Event Queue (cola de eventos) y el Event Loop (bucle de eventos). Estos componentes trabajan juntos para manejar de forma eficiente recursos concurrentes y no bloqueantes.

* La Event Queue es una estructura de datos donde el Event Demultiplexer coloca todos los eventos, listos para ser encolados y procesados secuencialmente por el Event Loop hasta que la cola quede vac√≠a.
* El Event Loop es un proceso que se ejecuta continuamente, espera mensajes en la Event Queue y luego los env√≠a a los controladores (handlers) correspondientes.

## ¬øProblema resuelto? ü•≥

Esto es lo que sucede cuando llamamos a una operaci√≥n de I/O:

1. Libuv inicializa el Event Demultiplexer apropiado seg√∫n el sistema operativo;
2. El int√©rprete de Node.js analiza el c√≥digo y coloca cada operaci√≥n en la pila de llamadas (call stack);
3. Node.js ejecuta las operaciones de la pila de llamadas de forma secuencial. Sin embargo, para las operaciones de I/O, Node.js las env√≠a al Event Demultiplexer de forma no bloqueante. Este enfoque garantiza que la operaci√≥n de I/O no bloquee el hilo, permitiendo que otras operaciones se ejecuten de manera concurrente;
4. El Event Demultiplexer identifica la fuente de la operaci√≥n de I/O y registra la operaci√≥n utilizando las capacidades del sistema operativo;
5. El Event Demultiplexer monitorea continuamente la fuente (por ejemplo, un socket de red) buscando eventos (por ejemplo, cuando hay datos disponibles para leer);
6. Cuando ocurre el evento (como que los datos est√©n listos para leerse), el Event Demultiplexer env√≠a una se√±al y agrega el evento junto con su _callback_ asociado a la Event Queue;
7. El Event Loop revisa continuamente la Event Queue y procesa el _callback_ del evento.

Lo que hace Node.js es que, mientras una solicitud est√° esperando, puede atender otra solicitud. Node.js no espera a que una solicitud se complete antes de procesar las dem√°s. Por defecto, todas las solicitudes que realizas en Node.js son concurrentes ‚Äî no esperan a que otras terminen antes de ejecutarse.

<figure><img src="../.gitbook/assets/image (28).png" alt=""><figcaption></figcaption></figure>

¬°Hurra! Parece que el problema est√° resuelto. Node.js puede ejecutarse de manera eficiente en un solo hilo, ya que la mayor√≠a de las complejidades relacionadas con las operaciones de I/O bloqueantes han sido resueltas por los desarrolladores de los sistemas operativos. ¬°Gracias!

## El problema NO est√° resuelto ü´†

Pero si observamos m√°s de cerca la estructura de libuv, encontramos un aspecto interesante:

<figure><img src="../.gitbook/assets/image (29).png" alt=""><figcaption></figcaption></figure>

¬øEspera‚Ä¶ un Thread Pool? ¬øQu√©? S√≠, ahora hemos profundizado lo suficiente como para responder la pregunta principal: ¬øPor qu√© Node.js no es (completamente) de un solo hilo?

## Revelando el secreto ü§´

Bien, tenemos una herramienta poderosa y utilidades del sistema operativo que nos permiten ejecutar c√≥digo as√≠ncrono en un solo hilo.

**Pero aqu√≠ aparece un problema** con el Event Demultiplexer. Dado que la implementaci√≥n del Event Demultiplexer var√≠a entre sistemas operativos, algunas partes de las operaciones de I/O no est√°n completamente soportadas de manera as√≠ncrona. Es dif√≠cil soportar todos los diferentes tipos de operaciones de I/O en todas las distintas plataformas de sistema operativo. Estos problemas est√°n especialmente relacionados con las implementaciones de I/O en archivos. Esto tambi√©n impacta algunas funciones DNS de Node.js.

Y no solo eso. Hay otros tipos de operaciones de I/O que no pueden completarse de manera as√≠ncrona, como por ejemplo:

* **Operaciones DNS**, como dns.lookup, que pueden bloquear porque podr√≠an necesitar consultar un servidor remoto;
* **Tareas intensivas de CPU**, como criptograf√≠a;
* **Compresi√≥n de archivos ZIP.**

Para este tipo de casos, se utiliza el Thread Pool para ejecutar las operaciones de I/O en hilos separados (t√≠picamente hay 4 hilos por defecto). As√≠ que, el diagrama completo de la arquitectura de Node.js se ver√≠a as√≠:

<figure><img src="../.gitbook/assets/image (30).png" alt=""><figcaption></figcaption></figure>

S√≠, Node.js en s√≠ es de un solo hilo, pero las bibliotecas que utiliza internamente, como libuv con su thread pool para algunas operaciones de I/O, no lo son.

El **Thread Pool**, en conjunto con la Tasks Queue (cola de tareas), se utiliza para manejar operaciones de I/O que son bloqueantes. Por defecto, el Thread Pool incluye 4 hilos, pero este comportamiento puede modificarse proporcionando una variable de entorno adicional:

```bash
UV_THREADPOOL_SIZE=8 node my_script.js
```

Esto es lo que ocurre cuando una operaci√≥n de I/O no puede realizarse de forma as√≠ncrona, pero las diferencias clave son:

* Cuando el Event Demultiplexer identifica la fuente de la operaci√≥n de I/O, registra la operaci√≥n en la **Tasks Queue** (cola de tareas);
* El Thread Pool monitorea continuamente la Tasks Queue en busca de nuevas tareas;
* Cuando se coloca una nueva tarea en la cola, el Thread Pool reacciona manej√°ndola con uno de los hilos predefinidos, de forma as√≠ncrona;
* Al finalizar la operaci√≥n, el Thread Pool env√≠a una se√±al y agrega el evento con su _callback_ asociado a la Event Queue (cola de eventos).

Aqu√≠ no hay magia. La I/O no puede ser verdaderamente no bloqueante y no hay forma de lograr eso (al menos por ahora). Los datos no pueden transferirse m√°s r√°pido de lo que lo permiten las limitaciones f√≠sicas. Nada es perfecto, as√≠ que hasta que encontremos maneras de aumentar la velocidad de transferencia de datos a nivel de hardware, utilizamos un conjunto de algoritmos optimizados para realizar operaciones as√≠ncronas de la forma m√°s eficiente posible.



